import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import io
import re
import os

# ==========================================
# 0. ç¶²é èˆ‡ç’°å¢ƒè¨­å®š
# ==========================================
st.set_page_config(
    page_title="äº¤æ˜“æç›Šåˆ†æå·¥å…· v9.0 (æœ€ä½³åŒ–ç‰ˆ)",
    page_icon="ğŸ“Š",
    layout="wide"
)

# è¨­å®šä¸­æ–‡å­—é«” (é¿å…åœ–è¡¨äº‚ç¢¼)
font_paths = fm.findSystemFonts(fontpaths=None, fontext='ttf')
CHINESE_FONT = 'Microsoft JhengHei' # é è¨­å¾®è»Ÿæ­£é»‘é«”
for font_path in font_paths:
    if 'msjh.ttc' in font_path or 'msjh.ttf' in font_path:
        CHINESE_FONT = 'Microsoft JhengHei'
        break
    elif 'Heiti' in font_path or 'SimHei' in font_path:
        CHINESE_FONT = 'SimHei'

plt.rcParams['font.sans-serif'] = [CHINESE_FONT, 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. æ ¸å¿ƒè¨ˆç®—å‡½å¼åº«
# ==========================================

def calculate_drawdown_info(equity_curve_series):
    """è¨ˆç®—æœ€å¤§å›æª” (MDD)"""
    peak = equity_curve_series.expanding(min_periods=1).max()
    drawdown = peak - equity_curve_series
    drawdown_percent = (drawdown / peak).fillna(0)
    max_drawdown_value = drawdown.max()
    max_drawdown_percent = drawdown_percent.max()
    return max_drawdown_value, max_drawdown_percent, drawdown

def calculate_consecutive(pnl_series):
    """è¨ˆç®—æœ€å¤§é€£å‹èˆ‡é€£æ•—æ¬¡æ•¸"""
    if pnl_series.empty: return 0, 0
    is_win = pnl_series > 0
    groups = is_win.ne(is_win.shift()).cumsum()
    streaks = groups.map(groups.value_counts())
    max_wins = streaks[is_win].max() if not streaks[is_win].empty else 0
    max_losses = streaks[~is_win].max() if not streaks[~is_win].empty else 0
    return int(max_wins), int(max_losses)

@st.cache_data
def run_monte_carlo_simulation(pnl_series, n_simulations=1000, n_trades=None):
    """åŸ·è¡Œè’™åœ°å¡ç¾…æ¨¡æ“¬"""
    if n_trades is None: n_trades = len(pnl_series)
    pnl_array = pnl_series.to_numpy()
    # å»ºç«‹çŸ©é™£: åˆ—=äº¤æ˜“æ¬¡æ•¸, æ¬„=æ¨¡æ“¬æ¬¡æ•¸
    sim_results_matrix = np.zeros((n_trades, n_simulations))
    for i in range(n_simulations):
        # éš¨æ©Ÿé‡çµ„äº¤æ˜“
        random_trades = np.random.choice(pnl_array, size=n_trades, replace=True)
        sim_results_matrix[:, i] = np.cumsum(random_trades)
    
    sim_df = pd.DataFrame(sim_results_matrix)
    final_equities = sim_df.iloc[-1, :] # å–æœ€å¾Œä¸€ç­†ä½œç‚ºæœ€çµ‚æ·¨å€¼
    return sim_df, final_equities

def calculate_risk_metrics(df, date_col, pnl_col, initial_capital):
    """è¨ˆç®—å¤æ™®æ¯”ç‡ã€é¢¨å ±æ¯”ã€å¹´åŒ–æ³¢å‹•ç‡èˆ‡æ¬Šç›Šæ›²ç·š"""
    df = df.sort_values(by=date_col)
    daily_pnl = df.groupby(date_col)[pnl_col].sum()
    if daily_pnl.empty: return 0.0, 0.0, None, 0.0

    # è£œé½Šéäº¤æ˜“æ—¥ï¼Œä½¿æ™‚é–“åºåˆ—é€£çºŒ
    idx = pd.date_range(start=daily_pnl.index.min(), end=daily_pnl.index.max())
    daily_pnl = daily_pnl.reindex(idx, fill_value=0)
    
    # è¨ˆç®—æ¬Šç›Šæ›²ç·š (åˆå§‹è³‡é‡‘ + ç´¯è¨ˆæç›Š)
    equity_curve = initial_capital + daily_pnl.cumsum()
    daily_returns = equity_curve.pct_change().fillna(0)
    
    # å¹´åŒ–æ³¢å‹•ç‡
    std_dev = daily_returns.std()
    annualized_volatility = std_dev * np.sqrt(252)
    
    # å¤æ™®æ¯”ç‡ (å‡è¨­ç„¡é¢¨éšªåˆ©ç‡ç‚º0)
    if std_dev == 0: sharpe_ratio = 0.0
    else: sharpe_ratio = (daily_returns.mean() / std_dev) * np.sqrt(252)
        
    # é¢¨å ±æ¯” (åªçœ‹ä¸‹æª”é¢¨éšª)
    downside_returns = daily_returns[daily_returns < 0]
    downside_std = downside_returns.std()
    if downside_std == 0 or pd.isna(downside_std):
        sortino_ratio = float('inf') if daily_returns.mean() > 0 else 0.0
    else:
        sortino_ratio = (daily_returns.mean() / downside_std) * np.sqrt(252)
        
    return sharpe_ratio, sortino_ratio, equity_curve, annualized_volatility

# ==========================================
# 2. è³‡æ–™è®€å–èˆ‡å‰è™•ç†
# ==========================================

def load_data(uploaded_file):
    """è®€å–æª”æ¡ˆ (è‡ªå‹•å˜—è©¦å¤šç¨® CSV ç·¨ç¢¼)"""
    try:
        if uploaded_file.name.endswith('.csv'):
            uploaded_file.seek(0)
            # å¸¸è¦‹ç·¨ç¢¼é †åºï¼šé€šç”¨ -> Windows BOM -> ç¹é«”ä¸­æ–‡(èˆŠ) -> ç¹é«”ä¸­æ–‡(æ¨™æº–)
            encodings = ['utf-8', 'utf-8-sig', 'cp950', 'big5']
            for enc in encodings:
                try:
                    df = pd.read_csv(uploaded_file, encoding=enc)
                    uploaded_file.seek(0)
                    return df
                except UnicodeDecodeError:
                    uploaded_file.seek(0)
                    continue
            return None
        else:
            return pd.read_excel(uploaded_file)
    except Exception:
        return None

def preprocess_xq_data(df):
    """è­˜åˆ¥ä¸¦æ¸…ç† XQ å ±è¡¨æ ¼å¼ (å€‹è‚¡/æœŸè²¨)"""
    df.columns = df.columns.str.strip().str.replace('"', '').str.strip()
    
    # è‡ªå‹•åˆ¤æ–·æ¬„ä½åç¨±
    if 'ç­†æ•¸' in df.columns and 'æ·¨æç›Š' in df.columns:
        # æœŸè²¨æ ¼å¼
        date_col, pnl_col, trade_id_col = 'äº¤æ˜“æ—¥æœŸ', 'æ·¨æç›Š', 'ç­†æ•¸'
    elif 'æç›Šé‡‘é¡' in df.columns:
        # å€‹è‚¡æ ¼å¼ ('åºè™Ÿ'å¯èƒ½ä¸å­˜åœ¨ï¼Œè‹¥ç„¡å‰‡ç”¨None)
        date_col, pnl_col = 'äº¤æ˜“æ—¥æœŸ', 'æç›Šé‡‘é¡'
        trade_id_col = 'åºè™Ÿ' if 'åºè™Ÿ' in df.columns else None
    else:
        return None, None, None, None

    # æ ¼å¼è½‰æ›
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df[pnl_col] = pd.to_numeric(df[pnl_col].astype(str).str.strip(), errors='coerce').fillna(0)
    
    if trade_id_col and trade_id_col in df.columns:
        df[trade_id_col] = pd.to_numeric(df[trade_id_col].astype(str).str.strip(), errors='coerce')
    
    # ç§»é™¤ç„¡æ•ˆæ—¥æœŸ
    df.dropna(subset=[date_col], inplace=True)
    
    # æ’åº
    df = df.sort_values(by=date_col).reset_index(drop=True)
    return df, date_col, pnl_col, trade_id_col

# ==========================================
# 3. æ¨¡å¼ä¸€ï¼šå–®ä¸€å ±è¡¨åˆ†æ (MC é¢¨æ ¼)
# ==========================================

def perform_single_report_analysis(df_cleaned, pnl_col, date_col, trade_id_col, initial_capital, report_title):
    
    # 1. åŸºç¤æ•¸æ“š
    pnl_events = df_cleaned[df_cleaned[pnl_col] != 0]
    
    # è¨ˆç®—ç¸½äº¤æ˜“æ¬¡æ•¸ (è‹¥æœ‰ç·¨è™Ÿå‰‡å»é‡ï¼Œå¦å‰‡ç®—ç­†æ•¸)
    if trade_id_col:
        total_trades = df_cleaned[trade_id_col].nunique()
    else:
        total_trades = len(pnl_events)
    
    profitable = pnl_events[pnl_events[pnl_col] > 0]
    losing = pnl_events[pnl_events[pnl_col] < 0]
    
    num_wins = len(profitable)
    num_losses = len(losing)
    realized_trades = num_wins + num_losses
    win_rate = (num_wins / realized_trades * 100) if realized_trades > 0 else 0
    
    # 2. æç›ŠæŒ‡æ¨™
    net_profit = df_cleaned[pnl_col].sum()
    gross_profit = profitable[pnl_col].sum()
    gross_loss = abs(losing[pnl_col].sum())
    pf = gross_profit / gross_loss if gross_loss > 0 else float('inf')
    
    avg_win = gross_profit / num_wins if num_wins > 0 else 0
    avg_loss = gross_loss / num_losses if num_losses > 0 else 0
    avg_trade = net_profit / total_trades if total_trades > 0 else 0
    ratio_wl = avg_win / avg_loss if avg_loss > 0 else float('inf')
    
    # é€£å‹é€£æ•—
    max_con_w, max_con_l = calculate_consecutive(pnl_events[pnl_col])
    
    # 3. é¢¨éšªæŒ‡æ¨™
    sharpe, sortino, equity_curve, volatility = calculate_risk_metrics(df_cleaned, date_col, pnl_col, initial_capital)
    
    if equity_curve is None:
        st.error("ç„¡æ³•è¨ˆç®—é¢¨éšªæŒ‡æ¨™ï¼Œè«‹æª¢æŸ¥æ—¥æœŸèˆ‡æç›Šæ•¸æ“šã€‚")
        return
        
    mdd_val, mdd_pct, underwater = calculate_drawdown_info(equity_curve)
    total_return = (net_profit / initial_capital) * 100

    # --- é¡¯ç¤ºå ±å‘Š ---
    st.header(f"ç­–ç•¥ç¸¾æ•ˆå ±å‘Š ({report_title})")
    
    st.subheader("1. å…¨æœŸæç›Šåˆ†æ (Performance Summary)")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("ç¸½æ·¨åˆ© (Net Profit)", f"${net_profit:,.0f}")
    c2.metric("æ¯›åˆ© (Gross Profit)", f"${gross_profit:,.0f}")
    c3.metric("æ¯›æ (Gross Loss)", f"${gross_loss:,.0f}")
    c4.metric("ç²åˆ©å› å­ (PF)", f"{pf:.2f}")
    c5.metric("ç¸½å ±é…¬ç‡ (ROI)", f"{total_return:.2f}%")
    
    st.markdown("---")
    
    st.subheader("2. äº¤æ˜“åˆ†æ (Trade Analysis)")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ç¸½äº¤æ˜“æ¬¡æ•¸", f"{total_trades}")
    c2.metric("å‹ç‡ (Win Rate)", f"{win_rate:.2f}%")
    c3.metric("å¹³å‡å–®ç­†æç›Š", f"${avg_trade:,.0f}")
    c4.metric("å¹³å‡è³ºè³ æ¯”", f"{ratio_wl:.2f}")
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ç²åˆ©æ¬¡æ•¸", f"{num_wins}")
    c2.metric("è™§ææ¬¡æ•¸", f"{num_losses}")
    c3.metric("æœ€å¤§é€£å‹", f"{max_con_w} æ¬¡")
    c4.metric("æœ€å¤§é€£æ•—", f"{max_con_l} æ¬¡")
    
    st.markdown("---")
    
    st.subheader("3. é¢¨éšªåˆ†æ (Risk Analysis)")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å¤æ™®æ¯”ç‡ (Sharpe)", f"{sharpe:.2f}")
    c2.metric("é¢¨å ±æ¯” (Sortino)", f"{sortino:.2f}")
    c3.metric("å¹´åŒ–æ³¢å‹•ç‡", f"{volatility*100:.2f}%")
    c4.metric("æœ€å¤§ç­–ç•¥å›æª” ($)", f"${mdd_val:,.0f}")
    
    # è£œä¸Š MDD%
    c1, c2 = st.columns(2)
    c1.metric("æœ€å¤§ç­–ç•¥å›æª” (%)", f"{mdd_pct*100:.2f}%")
    
    st.markdown("---")

    # --- åœ–è¡¨ ---
    st.subheader("4. æ¬Šç›Šæ›²ç·šèˆ‡å›æª”")
    c1, c2 = st.columns(2)
    with c1:
        fig, ax = plt.subplots(figsize=(10, 5))
        eq_df = equity_curve.reset_index()
        eq_df.columns = ['Date', 'Equity']
        ax.plot(eq_df['Date'], eq_df['Equity'], color='#1f77b4', linewidth=1.5)
        # æ¨™ç¤ºåˆå§‹è³‡é‡‘ç·š
        ax.axhline(y=initial_capital, color='gray', linestyle='--', alpha=0.5)
        ax.fill_between(eq_df['Date'], eq_df['Equity'], initial_capital, where=(eq_df['Equity'] >= initial_capital), facecolor='green', alpha=0.1)
        ax.fill_between(eq_df['Date'], eq_df['Equity'], initial_capital, where=(eq_df['Equity'] < initial_capital), facecolor='red', alpha=0.1)
        ax.set_title(f"æ¬Šç›Šæ›²ç·š (åˆå§‹: ${initial_capital:,.0f})")
        ax.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig)
    
    with c2:
        fig2, ax2 = plt.subplots(figsize=(10, 5))
        ax2.fill_between(underwater.index, -underwater, 0, facecolor='red', alpha=0.7)
        ax2.set_title("æ°´ä¸‹åœ– (Drawdown)")
        ax2.set_ylabel("å›æª”é‡‘é¡ ($)")
        ax2.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig2)

    st.markdown("---")
    
    # --- è’™åœ°å¡ç¾… ---
    st.subheader("5. è’™åœ°å¡ç¾…æ¨¡æ“¬ (Monte Carlo)")
    n_sims = st.number_input("æ¨¡æ“¬æ¬¡æ•¸", 100, 5000, 1000, 100)
    if st.button(f"åŸ·è¡Œ {n_sims} æ¬¡æ¨¡æ“¬"):
        with st.spinner("æ¨¡æ“¬é‹ç®—ä¸­..."):
            sim_df, final_eq = run_monte_carlo_simulation(pnl_events[pnl_col], n_sims, len(pnl_events))
            
            fig3, ax3 = plt.subplots(figsize=(12, 6))
            ax3.plot(sim_df, color='lightblue', alpha=0.05)
            # åŸå§‹æ›²ç·š
            original_curve = pnl_events[pnl_col].cumsum().reset_index(drop=True)
            ax3.plot(original_curve, color='red', linewidth=2, label="åŸå§‹ç­–ç•¥")
            ax3.set_title("è’™åœ°å¡ç¾…è·¯å¾‘")
            ax3.legend()
            st.pyplot(fig3)
            
            c1, c2, c3 = st.columns(3)
            c1.metric("åŸå§‹çµå­˜", f"${net_profit:,.0f}")
            c2.metric("æ¨¡æ“¬ä¸­ä½æ•¸", f"${final_eq.median():,.0f}")
            c3.metric("5% æœ€å·®çµå­˜", f"${final_eq.quantile(0.05):,.0f}")

# ==========================================
# 4. æ¨¡å¼äºŒï¼šæœ€ä½³åŒ–åˆ†æ (Batch Optimization)
# ==========================================

def parse_filename_params(filename):
    """
    å¾æª”åè§£æåƒæ•¸ã€‚
    é‚è¼¯ï¼šæŠ“å–æª”åä¸­çš„æ‰€æœ‰æ•¸å­—ã€‚
    é è¨­ç¬¬1å€‹æ•¸å­—ç‚º Param1ï¼Œç¬¬2å€‹ç‚º Param2ã€‚
    """
    name_no_ext = os.path.splitext(filename)[0]
    # æŠ“å–æ•´æ•¸æˆ–å°æ•¸
    numbers = re.findall(r"[-+]?\d*\.\d+|\d+", name_no_ext)
    params = {}
    if numbers:
        params['Param1'] = float(numbers[0])
        if len(numbers) > 1:
            params['Param2'] = float(numbers[1])
    else:
        params['Param1'] = name_no_ext # ç„¡æ•¸å­—å‰‡ç”¨æª”å
    return params

def analyze_optimization_batch(uploaded_files, initial_capital):
    
    results = []
    progress_bar = st.progress(0)
    
    st.info(f"æ­£åœ¨åˆ†æ {len(uploaded_files)} å€‹æª”æ¡ˆ...")
    
    for i, file in enumerate(uploaded_files):
        # 1. è®€å–
        df = load_data(file)
        if df is None: continue
        
        # 2. æ¸…ç†èˆ‡è­˜åˆ¥
        df_clean, date_col, pnl_col, trade_id_col = preprocess_xq_data(df)
        if df_clean is None: continue
        
        # 3. è¨ˆç®—æ ¸å¿ƒæŒ‡æ¨™
        net_profit = df_clean[pnl_col].sum()
        total_trades = df_clean[trade_id_col].nunique() if trade_id_col else len(df_clean[df_clean[pnl_col]!=0])
        
        sharpe, sortino, equity, vol = calculate_risk_metrics(df_clean, date_col, pnl_col, initial_capital)
        mdd_val, mdd_pct, _ = calculate_drawdown_info(equity) if equity is not None else (0, 0, None)
        
        # 4. è§£æåƒæ•¸
        params = parse_filename_params(file.name)
        
        # 5. å­˜å…¥åˆ—è¡¨
        record = {
            'Filename': file.name,
            'Net Profit': net_profit,
            'Sharpe': sharpe,
            'MDD %': mdd_pct * 100,
            'Trades': total_trades,
            'Win Rate': 0 # ç°¡åŒ–ï¼Œæš«ä¸è¨ˆç®—
        }
        record.update(params)
        results.append(record)
        
        progress_bar.progress((i + 1) / len(uploaded_files))
        
    if not results:
        st.error("ç„¡æ³•è®€å–ä»»ä½•æœ‰æ•ˆæ•¸æ“šï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼ã€‚")
        return

    res_df = pd.DataFrame(results)
    
    # --- é¡¯ç¤ºæœ€ä½³åŒ–å ±å‘Š ---
    st.header("ğŸ”¬ ç­–ç•¥æœ€ä½³åŒ–åˆ†æ (Optimization Report)")
    
    # 1. åƒæ•¸é«˜åŸåœ–
    st.subheader("1. åƒæ•¸é«˜åŸåˆ†æ (Parameter Plateau)")
    
    c1, c2 = st.columns(2)
    x_axis = c1.selectbox("é¸æ“‡ X è»¸ (åƒæ•¸)", ['Param1', 'Param2'] if 'Param2' in res_df.columns else ['Param1'])
    y_axis = c2.selectbox("é¸æ“‡ Y è»¸ (ç¸¾æ•ˆ)", ['Net Profit', 'Sharpe', 'MDD %'])
    
    # æ’åº
    chart_data = res_df.sort_values(by=x_axis)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # åˆ¤æ–·æ˜¯å¦ç‚º 2D ç†±åŠ›åœ–éœ€æ±‚ (è‹¥æœ‰ Param2 ä¸”é¸ Param1 ç‚º X)
    if 'Param2' in res_df.columns and x_axis == 'Param1':
        # æ•£ä½ˆåœ– (é¡è‰²ä»£è¡¨ç¸¾æ•ˆ)
        sc = ax.scatter(chart_data[x_axis], chart_data['Param2'], c=chart_data[y_axis], cmap='viridis', s=150, edgecolors='black')
        plt.colorbar(sc, label=y_axis)
        ax.set_ylabel("Param2")
        ax.set_title(f"{y_axis} Heatmap (Param1 vs Param2)")
    else:
        # å–®åƒæ•¸æŠ˜ç·šåœ–
        ax.plot(chart_data[x_axis], chart_data[y_axis], marker='o', linestyle='-', color='#1f77b4', linewidth=2)
        # æ¨™ç¤ºæœ€é«˜é»
        max_idx = chart_data[y_axis].idxmax()
        ax.annotate(f'Max: {chart_data.loc[max_idx, y_axis]:.2f}', 
                    xy=(chart_data.loc[max_idx, x_axis], chart_data.loc[max_idx, y_axis]),
                    xytext=(10, 10), textcoords='offset points', arrowprops=dict(arrowstyle='->', color='red'))
        ax.set_ylabel(y_axis)
        ax.set_title(f"{y_axis} vs {x_axis}")

    ax.set_xlabel(x_axis)
    ax.grid(True, linestyle='--', alpha=0.6)
    st.pyplot(fig)
    
    # 2. è©³ç´°æ•¸æ“šè¡¨
    st.subheader("2. è©³ç´°æ•¸æ“šåˆ—è¡¨")
    # é«˜äº®é¡¯ç¤ºè¼ƒå¥½çš„æ•¸å€¼
    st.dataframe(res_df.style.background_gradient(subset=['Net Profit', 'Sharpe'], cmap='Greens'))
    
    # 3. æœ€ä½³åƒæ•¸
    best = res_df.loc[res_df['Net Profit'].idxmax()]
    st.success(f"ğŸ† æœ€ä½³æ·¨åˆ©åƒæ•¸: {best[x_axis]} (æ·¨åˆ©: ${best['Net Profit']:,.0f}, å¤æ™®: {best['Sharpe']:.2f})")


# ==========================================
# 5. ä¸»ç¨‹å¼å…¥å£
# ==========================================

st.title("ğŸ“Š äº¤æ˜“æç›Šåˆ†æå·¥å…· v9.0")

st.subheader("1. è¨­å®šèˆ‡æ¨¡å¼")
col1, col2 = st.columns([1, 2])
with col1:
    initial_capital = st.number_input("åˆå§‹è³‡é‡‘ (Initial Capital)", value=3000000, step=10000)
with col2:
    mode = st.radio("é¸æ“‡åŠŸèƒ½æ¨¡å¼", ["å–®ä¸€å ±è¡¨åˆ†æ (MCé¢¨æ ¼)", "XQ ç­–ç•¥æœ€ä½³åŒ– (æ‰¹æ¬¡CSV)"], horizontal=True)

st.markdown("---")

if mode == "å–®ä¸€å ±è¡¨åˆ†æ (MCé¢¨æ ¼)":
    st.subheader("2. ä¸Šå‚³å–®ä¸€å ±è¡¨ (Excel/CSV)")
    file = st.file_uploader("é¸æ“‡æª”æ¡ˆ", type=["xlsx", "xls", "csv"])
    if file:
        df = load_data(file)
        if df is not None:
            df_clean, date_col, pnl_col, trade_id_col = preprocess_xq_data(df)
            if df_clean is not None:
                r_type = "æœŸè²¨" if 'ç­†æ•¸' in df.columns else "å€‹è‚¡"
                perform_single_report_analysis(df_clean, pnl_col, date_col, trade_id_col, initial_capital, r_type)
            else:
                st.error("æ ¼å¼ç„¡æ³•è­˜åˆ¥ï¼Œè«‹ç¢ºèªæ˜¯å¦ç‚º XQ åŒ¯å‡ºçš„äº¤æ˜“æ˜ç´°ã€‚")
        else:
            st.error("æª”æ¡ˆè®€å–å¤±æ•—ã€‚")

else: # æœ€ä½³åŒ–æ¨¡å¼
    st.subheader("2. æ‰¹æ¬¡ä¸Šå‚³å¤šå€‹å›æ¸¬ CSV")
    st.info("ğŸ’¡ æç¤ºï¼šè«‹å°‡æª”åå‘½åç‚º `åƒæ•¸1_åƒæ•¸2.csv` (ä¾‹å¦‚ `MA_60.csv` æˆ– `MA60_Stop20.csv`)ï¼Œç¨‹å¼æœƒè‡ªå‹•æŠ“å–æ•¸å­—ä½œç‚ºåƒæ•¸ã€‚")
    files = st.file_uploader("é¸æ“‡å¤šå€‹æª”æ¡ˆ (å¯æ‹–æ›³)", type=["csv"], accept_multiple_files=True)
    
    if files:
        analyze_optimization_batch(files, initial_capital)
