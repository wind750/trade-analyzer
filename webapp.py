import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import io
import re
import os

# ==========================================
# 0. ç¶²é èˆ‡ç’°å¢ƒè¨­å®š
# ==========================================
st.set_page_config(
    page_title="äº¤æ˜“æç›Šåˆ†æå·¥å…· v9.3 (å¤šå·¥ä½œè¡¨æœå°‹ç‰ˆ)",
    page_icon="ğŸ“Š",
    layout="wide"
)

# è¨­å®šä¸­æ–‡å­—é«”
font_paths = fm.findSystemFonts(fontpaths=None, fontext='ttf')
CHINESE_FONT = 'Microsoft JhengHei' 
for font_path in font_paths:
    if 'msjh.ttc' in font_path or 'msjh.ttf' in font_path:
        CHINESE_FONT = 'Microsoft JhengHei'
        break
    elif 'Heiti' in font_path or 'SimHei' in font_path:
        CHINESE_FONT = 'SimHei'

plt.rcParams['font.sans-serif'] = [CHINESE_FONT, 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

# ==========================================
# 1. æ ¸å¿ƒè¨ˆç®—å‡½å¼åº« (ä¿æŒä¸è®Š)
# ==========================================

def calculate_drawdown_info(equity_curve_series):
    peak = equity_curve_series.expanding(min_periods=1).max()
    drawdown = peak - equity_curve_series
    drawdown_percent = (drawdown / peak).fillna(0)
    max_drawdown_value = drawdown.max()
    max_drawdown_percent = drawdown_percent.max()
    return max_drawdown_value, max_drawdown_percent, drawdown

def calculate_consecutive(pnl_series):
    if pnl_series.empty: return 0, 0
    is_win = pnl_series > 0
    groups = is_win.ne(is_win.shift()).cumsum()
    streaks = groups.map(groups.value_counts())
    max_wins = streaks[is_win].max() if not streaks[is_win].empty else 0
    max_losses = streaks[~is_win].max() if not streaks[~is_win].empty else 0
    return int(max_wins), int(max_losses)

@st.cache_data
def run_monte_carlo_simulation(pnl_series, n_simulations=1000, n_trades=None):
    if n_trades is None: n_trades = len(pnl_series)
    pnl_array = pnl_series.to_numpy()
    sim_results_matrix = np.zeros((n_trades, n_simulations))
    for i in range(n_simulations):
        random_trades = np.random.choice(pnl_array, size=n_trades, replace=True)
        sim_results_matrix[:, i] = np.cumsum(random_trades)
    sim_df = pd.DataFrame(sim_results_matrix)
    final_equities = sim_df.iloc[-1, :]
    return sim_df, final_equities

def calculate_risk_metrics(df, date_col, pnl_col, initial_capital):
    df = df.sort_values(by=date_col)
    daily_pnl = df.groupby(date_col)[pnl_col].sum()
    if daily_pnl.empty: return 0.0, 0.0, None, 0.0

    idx = pd.date_range(start=daily_pnl.index.min(), end=daily_pnl.index.max())
    daily_pnl = daily_pnl.reindex(idx, fill_value=0)
    
    equity_curve = initial_capital + daily_pnl.cumsum()
    daily_returns = equity_curve.pct_change().fillna(0)
    
    std_dev = daily_returns.std()
    annualized_volatility = std_dev * np.sqrt(252)
    
    if std_dev == 0: sharpe_ratio = 0.0
    else: sharpe_ratio = (daily_returns.mean() / std_dev) * np.sqrt(252)
        
    downside_returns = daily_returns[daily_returns < 0]
    downside_std = downside_returns.std()
    
    if downside_std == 0 or pd.isna(downside_std):
        sortino_ratio = float('inf') if daily_returns.mean() > 0 else 0.0
    else:
        sortino_ratio = (daily_returns.mean() / downside_std) * np.sqrt(252)
        
    return sharpe_ratio, sortino_ratio, equity_curve, annualized_volatility

# ==========================================
# 2. è³‡æ–™è®€å–èˆ‡å‰è™•ç† (v9.3 å¤šSheetæœå°‹)
# ==========================================

def find_header_and_clean(df):
    """
    æ™ºæ…§æœå°‹æ¨™é¡Œåˆ— (å¾€ä¸‹æƒæ 30 è¡Œ)
    """
    header_idx = -1
    # æª¢æŸ¥æ˜¯å¦åŒ…å«é—œéµæ¬„ä½
    target_cols = ['äº¤æ˜“æ—¥æœŸ', 'æ—¥æœŸ', 'Date']
    
    # 1. æª¢æŸ¥ç•¶å‰ column
    current_cols = df.columns.astype(str).str.strip().str.replace('"', '')
    if any(col in current_cols for col in target_cols):
        df.columns = current_cols
        return df

    # 2. å¾€ä¸‹æƒæ
    for i in range(min(30, len(df))):
        row_values = df.iloc[i].astype(str).str.strip().str.replace('"', '').tolist()
        if any(col in row_values for col in target_cols):
            header_idx = i
            break
            
    if header_idx != -1:
        new_header = df.iloc[header_idx].astype(str).str.strip().str.replace('"', '')
        df = df[header_idx + 1:].copy()
        df.columns = new_header
        return df.reset_index(drop=True)
    
    return None

def check_if_trade_data(df):
    """
    æª¢æŸ¥é€™å€‹ DataFrame æ˜¯å¦åƒæ˜¯ä¸€å€‹äº¤æ˜“æ˜ç´°è¡¨
    æ¢ä»¶ï¼šå¿…é ˆæœ‰ 'äº¤æ˜“æ—¥æœŸ' ä¸” (æœ‰ 'æ·¨æç›Š' æˆ– 'æç›Šé‡‘é¡')
    """
    if df is None: return False
    cols = df.columns
    has_date = 'äº¤æ˜“æ—¥æœŸ' in cols
    has_pnl = ('æ·¨æç›Š' in cols) or ('æç›Šé‡‘é¡' in cols)
    return has_date and has_pnl

def load_data_smart(uploaded_file):
    """
    â˜… v9.3 æ ¸å¿ƒï¼šè®€å–æª”æ¡ˆï¼Œå¦‚æœæ˜¯ Excelï¼Œæœƒéæ­·æ‰€æœ‰ Sheet å°‹æ‰¾äº¤æ˜“æ˜ç´°
    """
    try:
        # --- CSV è™•ç† ---
        if uploaded_file.name.lower().endswith('.csv'):
            uploaded_file.seek(0)
            encodings = ['utf-8', 'utf-8-sig', 'cp950', 'big5']
            for enc in encodings:
                try:
                    df = pd.read_csv(uploaded_file, encoding=enc)
                    uploaded_file.seek(0)
                    # å˜—è©¦æ¸…ç†ä¸¦æª¢æŸ¥
                    df_clean = find_header_and_clean(df)
                    if check_if_trade_data(df_clean):
                        return df_clean # æ‰¾åˆ°æ­£ç¢ºè³‡æ–™
                except UnicodeDecodeError:
                    uploaded_file.seek(0)
                    continue
            return None

        # --- Excel è™•ç† (å¤š Sheet æƒæ) ---
        else:
            excel_file = pd.ExcelFile(uploaded_file)
            sheet_names = excel_file.sheet_names
            
            # éæ­·æ¯ä¸€å€‹ Sheet
            for sheet in sheet_names:
                try:
                    df = pd.read_excel(uploaded_file, sheet_name=sheet)
                    # å˜—è©¦æ¸…ç†ä¸¦å°‹æ‰¾æ¨™é¡Œ
                    df_clean = find_header_and_clean(df)
                    # æª¢æŸ¥é€™å¼µè¡¨æ˜¯å¦åŒ…å«æˆ‘å€‘éœ€è¦çš„æ¬„ä½
                    if check_if_trade_data(df_clean):
                        # print(f"Found trade data in sheet: {sheet}") # Debugç”¨
                        return df_clean
                except Exception:
                    continue
            
            # å¦‚æœéƒ½æ²’æ‰¾åˆ°ï¼Œå›å‚³ None
            return None

    except Exception:
        return None

def preprocess_xq_data(df):
    """
    æœ€å¾Œè™•ç†ï¼šç¢ºèªæ¬„ä½å°æ‡‰
    æ³¨æ„ï¼šå‚³å…¥çš„ df æ‡‰è©²å·²ç¶“æ˜¯ç¶“é load_data_smart æ¸…ç†éæ¨™é¡Œçš„ df
    """
    if df is None: return None, None, None, None

    df.columns = df.columns.str.strip()
    
    if 'ç­†æ•¸' in df.columns and 'æ·¨æç›Š' in df.columns:
        date_col, pnl_col, trade_id_col = 'äº¤æ˜“æ—¥æœŸ', 'æ·¨æç›Š', 'ç­†æ•¸'
    elif 'æç›Šé‡‘é¡' in df.columns:
        date_col, pnl_col = 'äº¤æ˜“æ—¥æœŸ', 'æç›Šé‡‘é¡'
        trade_id_col = 'åºè™Ÿ' if 'åºè™Ÿ' in df.columns else None
    else:
        return None, None, None, None

    # æ ¼å¼è½‰æ›
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df[pnl_col] = pd.to_numeric(df[pnl_col].astype(str).str.strip(), errors='coerce').fillna(0)
    
    if trade_id_col and trade_id_col in df.columns:
        df[trade_id_col] = pd.to_numeric(df[trade_id_col].astype(str).str.strip(), errors='coerce')
    
    df.dropna(subset=[date_col], inplace=True)
    df = df.sort_values(by=date_col).reset_index(drop=True)
    return df, date_col, pnl_col, trade_id_col

# ==========================================
# 3. æ¨¡å¼ä¸€ï¼šå–®ä¸€å ±è¡¨åˆ†æ (MC é¢¨æ ¼)
# ==========================================

def perform_single_report_analysis(df_cleaned, pnl_col, date_col, trade_id_col, initial_capital, report_title):
    
    pnl_events = df_cleaned[df_cleaned[pnl_col] != 0]
    total_trades = df_cleaned[trade_id_col].nunique() if trade_id_col else len(pnl_events)
    
    profitable = pnl_events[pnl_events[pnl_col] > 0]
    losing = pnl_events[pnl_events[pnl_col] < 0]
    
    num_wins = len(profitable)
    num_losses = len(losing)
    realized_trades = num_wins + num_losses
    win_rate = (num_wins / realized_trades * 100) if realized_trades > 0 else 0
    
    net_profit = df_cleaned[pnl_col].sum()
    gross_profit = profitable[pnl_col].sum()
    gross_loss = abs(losing[pnl_col].sum())
    pf = gross_profit / gross_loss if gross_loss > 0 else float('inf')
    
    avg_win = gross_profit / num_wins if num_wins > 0 else 0
    avg_loss = gross_loss / num_losses if num_losses > 0 else 0
    avg_trade = net_profit / total_trades if total_trades > 0 else 0
    ratio_wl = avg_win / avg_loss if avg_loss > 0 else float('inf')
    
    max_con_w, max_con_l = calculate_consecutive(pnl_events[pnl_col])
    
    sharpe, sortino, equity_curve, volatility = calculate_risk_metrics(df_cleaned, date_col, pnl_col, initial_capital)
    
    if equity_curve is None:
        st.error("ç„¡æ³•è¨ˆç®—é¢¨éšªæŒ‡æ¨™ã€‚")
        return
        
    mdd_val, mdd_pct, underwater = calculate_drawdown_info(equity_curve)
    total_return = (net_profit / initial_capital) * 100

    # --- é¡¯ç¤ºå ±å‘Š ---
    st.header(f"ç­–ç•¥ç¸¾æ•ˆå ±å‘Š ({report_title})")
    
    st.subheader("1. å…¨æœŸæç›Šåˆ†æ")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("ç¸½æ·¨åˆ©", f"${net_profit:,.0f}")
    c2.metric("æ¯›åˆ©", f"${gross_profit:,.0f}")
    c3.metric("æ¯›æ", f"${gross_loss:,.0f}")
    c4.metric("ç²åˆ©å› å­", f"{pf:.2f}")
    c5.metric("ç¸½å ±é…¬ç‡", f"{total_return:.2f}%")
    
    st.markdown("---")
    st.subheader("2. äº¤æ˜“åˆ†æ")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ç¸½äº¤æ˜“æ¬¡æ•¸", f"{total_trades}")
    c2.metric("å‹ç‡", f"{win_rate:.2f}%")
    c3.metric("å¹³å‡å–®ç­†æç›Š", f"${avg_trade:,.0f}")
    c4.metric("å¹³å‡è³ºè³ æ¯”", f"{ratio_wl:.2f}")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ç²åˆ©æ¬¡æ•¸", f"{num_wins}")
    c2.metric("è™§ææ¬¡æ•¸", f"{num_losses}")
    c3.metric("æœ€å¤§é€£å‹", f"{max_con_w} æ¬¡")
    c4.metric("æœ€å¤§é€£æ•—", f"{max_con_l} æ¬¡")
    
    st.markdown("---")
    st.subheader("3. é¢¨éšªåˆ†æ")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("å¤æ™®æ¯”ç‡", f"{sharpe:.2f}")
    c2.metric("é¢¨å ±æ¯”", f"{sortino:.2f}")
    c3.metric("å¹´åŒ–æ³¢å‹•ç‡", f"{volatility*100:.2f}%")
    c4.metric("æœ€å¤§ç­–ç•¥å›æª” ($)", f"${mdd_val:,.0f}")
    c1, c2 = st.columns(2)
    c1.metric("æœ€å¤§ç­–ç•¥å›æª” (%)", f"{mdd_pct*100:.2f}%")
    
    st.markdown("---")
    st.subheader("4. æ¬Šç›Šæ›²ç·šèˆ‡å›æª”")
    c1, c2 = st.columns(2)
    with c1:
        fig, ax = plt.subplots(figsize=(10, 5))
        eq_df = equity_curve.reset_index()
        eq_df.columns = ['Date', 'Equity']
        ax.plot(eq_df['Date'], eq_df['Equity'], color='#1f77b4', linewidth=1.5)
        ax.axhline(y=initial_capital, color='gray', linestyle='--', alpha=0.5)
        ax.fill_between(eq_df['Date'], eq_df['Equity'], initial_capital, where=(eq_df['Equity'] >= initial_capital), facecolor='green', alpha=0.1)
        ax.fill_between(eq_df['Date'], eq_df['Equity'], initial_capital, where=(eq_df['Equity'] < initial_capital), facecolor='red', alpha=0.1)
        ax.set_title(f"æ¬Šç›Šæ›²ç·š (åˆå§‹: ${initial_capital:,.0f})")
        ax.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig)
    with c2:
        fig2, ax2 = plt.subplots(figsize=(10, 5))
        ax2.fill_between(underwater.index, -underwater, 0, facecolor='red', alpha=0.7)
        ax2.set_title("æ°´ä¸‹åœ– (Drawdown)")
        ax2.set_ylabel("å›æª”é‡‘é¡ ($)")
        ax2.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig2)

    st.markdown("---")
    st.subheader("5. è’™åœ°å¡ç¾…æ¨¡æ“¬")
    n_sims = st.number_input("æ¨¡æ“¬æ¬¡æ•¸", 100, 5000, 1000, 100)
    if st.button(f"åŸ·è¡Œ {n_sims} æ¬¡æ¨¡æ“¬"):
        with st.spinner("æ¨¡æ“¬é‹ç®—ä¸­..."):
            sim_df, final_eq = run_monte_carlo_simulation(pnl_events[pnl_col], n_sims, len(pnl_events))
            fig3, ax3 = plt.subplots(figsize=(12, 6))
            ax3.plot(sim_df, color='lightblue', alpha=0.05)
            original_curve = pnl_events[pnl_col].cumsum().reset_index(drop=True)
            ax3.plot(original_curve, color='red', linewidth=2, label="åŸå§‹ç­–ç•¥")
            ax3.set_title("è’™åœ°å¡ç¾…è·¯å¾‘")
            ax3.legend()
            st.pyplot(fig3)
            c1, c2, c3 = st.columns(3)
            c1.metric("åŸå§‹çµå­˜", f"${net_profit:,.0f}")
            c2.metric("æ¨¡æ“¬ä¸­ä½æ•¸", f"${final_eq.median():,.0f}")
            c3.metric("5% æœ€å·®çµå­˜", f"${final_eq.quantile(0.05):,.0f}")

# ==========================================
# 4. æ¨¡å¼äºŒï¼šæœ€ä½³åŒ–åˆ†æ (Batch Optimization)
# ==========================================

def parse_filename_params(filename):
    name_no_ext = os.path.splitext(filename)[0]
    numbers = re.findall(r"[-+]?\d*\.\d+|\d+", name_no_ext)
    params = {}
    if numbers:
        params['Param1'] = float(numbers[0])
        if len(numbers) > 1:
            params['Param2'] = float(numbers[1])
    else:
        params['Param1'] = name_no_ext
    return params

def analyze_optimization_batch(uploaded_files, initial_capital):
    
    results = []
    progress_bar = st.progress(0)
    st.info(f"æ­£åœ¨åˆ†æ {len(uploaded_files)} å€‹æª”æ¡ˆ...")
    
    for i, file in enumerate(uploaded_files):
        # â˜… v9.3 ä½¿ç”¨æ™ºæ…§è®€å– (load_data_smart)
        df_clean = load_data_smart(file)
        
        if df_clean is None: continue
        
        # å†æ¬¡æª¢æŸ¥æ¬„ä½ (ä»¥é˜²è¬ä¸€)
        df_ready, date_col, pnl_col, trade_id_col = preprocess_xq_data(df_clean)
        if df_ready is None: continue
        
        net_profit = df_ready[pnl_col].sum()
        total_trades = df_ready[trade_id_col].nunique() if trade_id_col else len(df_ready[df_ready[pnl_col]!=0])
        
        sharpe, sortino, equity, vol = calculate_risk_metrics(df_ready, date_col, pnl_col, initial_capital)
        mdd_val, mdd_pct, _ = calculate_drawdown_info(equity) if equity is not None else (0, 0, None)
        
        params = parse_filename_params(file.name)
        
        record = {
            'Filename': file.name,
            'Net Profit': net_profit,
            'Sharpe': sharpe,
            'MDD %': mdd_pct * 100,
            'Trades': total_trades,
        }
        record.update(params)
        results.append(record)
        progress_bar.progress((i + 1) / len(uploaded_files))
        
    if not results:
        st.error("ç„¡æ³•è®€å–æœ‰æ•ˆæ•¸æ“šã€‚ç¨‹å¼å·²å˜—è©¦æƒæ Excel çš„æ‰€æœ‰å·¥ä½œè¡¨ (Sheet)ï¼Œä»æœªæ‰¾åˆ°åŒ…å«ã€äº¤æ˜“æ—¥æœŸã€èˆ‡ã€æç›Šã€çš„è¡¨æ ¼ã€‚")
        return

    res_df = pd.DataFrame(results)
    
    st.header("ğŸ”¬ ç­–ç•¥æœ€ä½³åŒ–åˆ†æ (Optimization Report)")
    
    st.subheader("1. åƒæ•¸é«˜åŸåˆ†æ (Parameter Plateau)")
    c1, c2 = st.columns(2)
    x_axis = c1.selectbox("é¸æ“‡ X è»¸ (åƒæ•¸)", ['Param1', 'Param2'] if 'Param2' in res_df.columns else ['Param1'])
    y_axis = c2.selectbox("é¸æ“‡ Y è»¸ (ç¸¾æ•ˆ)", ['Net Profit', 'Sharpe', 'MDD %'])
    
    chart_data = res_df.sort_values(by=x_axis)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    if 'Param2' in res_df.columns and x_axis == 'Param1':
        sc = ax.scatter(chart_data[x_axis], chart_data['Param2'], c=chart_data[y_axis], cmap='viridis', s=150, edgecolors='black')
        plt.colorbar(sc, label=y_axis)
        ax.set_ylabel("Param2")
        ax.set_title(f"{y_axis} Heatmap (Param1 vs Param2)")
    else:
        ax.plot(chart_data[x_axis], chart_data[y_axis], marker='o', linestyle='-', color='#1f77b4', linewidth=2)
        max_idx = chart_data[y_axis].idxmax()
        ax.annotate(f'Max: {chart_data.loc[max_idx, y_axis]:.2f}', 
                    xy=(chart_data.loc[max_idx, x_axis], chart_data.loc[max_idx, y_axis]),
                    xytext=(10, 10), textcoords='offset points', arrowprops=dict(arrowstyle='->', color='red'))
        ax.set_ylabel(y_axis)
        ax.set_title(f"{y_axis} vs {x_axis}")

    ax.set_xlabel(x_axis)
    ax.grid(True, linestyle='--', alpha=0.6)
    st.pyplot(fig)
    
    st.subheader("2. è©³ç´°æ•¸æ“šåˆ—è¡¨")
    st.dataframe(res_df.style.background_gradient(subset=['Net Profit', 'Sharpe'], cmap='Greens'))
    
    best = res_df.loc[res_df['Net Profit'].idxmax()]
    st.success(f"ğŸ† æœ€ä½³æ·¨åˆ©åƒæ•¸: {best[x_axis]} (æ·¨åˆ©: ${best['Net Profit']:,.0f}, å¤æ™®: {best['Sharpe']:.2f})")


# ==========================================
# 5. ä¸»ç¨‹å¼å…¥å£
# ==========================================

st.title("ğŸ“Š äº¤æ˜“æç›Šåˆ†æå·¥å…· v9.3 (å¤šå·¥ä½œè¡¨æœå°‹ç‰ˆ)")

st.subheader("1. è¨­å®šèˆ‡æ¨¡å¼")
col1, col2 = st.columns([1, 2])
with col1:
    initial_capital = st.number_input("åˆå§‹è³‡é‡‘ (Initial Capital)", value=3000000, step=10000)
with col2:
    mode = st.radio("é¸æ“‡åŠŸèƒ½æ¨¡å¼", ["å–®ä¸€å ±è¡¨åˆ†æ (MCé¢¨æ ¼)", "XQ ç­–ç•¥æœ€ä½³åŒ– (æ‰¹æ¬¡ä¸Šå‚³)"], horizontal=True)

st.markdown("---")

if mode == "å–®ä¸€å ±è¡¨åˆ†æ (MCé¢¨æ ¼)":
    st.subheader("2. ä¸Šå‚³å–®ä¸€å ±è¡¨ (Excel/CSV)")
    file = st.file_uploader("é¸æ“‡æª”æ¡ˆ", type=["xlsx", "xls", "csv"])
    if file:
        # â˜… v9.3 ä½¿ç”¨æ™ºæ…§è®€å– (load_data_smart)
        df_clean = load_data_smart(file)
        
        if df_clean is not None:
            # å†æ¬¡ç¶“éé è™•ç†ç¢ºèªæ¬„ä½
            df_ready, date_col, pnl_col, trade_id_col = preprocess_xq_data(df_clean)
            if df_ready is not None:
                r_type = "æœŸè²¨" if 'ç­†æ•¸' in df_ready.columns else "å€‹è‚¡"
                perform_single_report_analysis(df_ready, pnl_col, date_col, trade_id_col, initial_capital, r_type)
            else:
                st.error("æ‰¾åˆ°çš„å·¥ä½œè¡¨å…§å®¹ç„¡æ³•è­˜åˆ¥ã€‚è«‹ç¢ºèªåŒ…å«ã€Œäº¤æ˜“æ—¥æœŸã€èˆ‡ã€Œæ·¨æç›Šã€ç­‰æ¬„ä½ã€‚")
        else:
            st.error("è®€å–å¤±æ•—ï¼šç„¡æ³•åœ¨ Excel çš„ä»»ä½•å·¥ä½œè¡¨ä¸­æ‰¾åˆ°äº¤æ˜“æ˜ç´°ã€‚")

else: # æœ€ä½³åŒ–æ¨¡å¼
    st.subheader("2. æ‰¹æ¬¡ä¸Šå‚³å¤šå€‹å›æ¸¬å ±è¡¨ (Excel/CSV)")
    st.info("ğŸ’¡ æç¤ºï¼šè«‹å°‡æª”åå‘½åç‚º `åƒæ•¸1.xlsx` (ä¾‹å¦‚ `60.xlsx`)ï¼Œç¨‹å¼æœƒè‡ªå‹•æŠ“å–æ•¸å­—ä½œç‚ºåƒæ•¸ã€‚")
    files = st.file_uploader("é¸æ“‡å¤šå€‹æª”æ¡ˆ (å¯æ‹–æ›³)", type=["csv", "xlsx", "xls"], accept_multiple_files=True)
    
    if files:
        analyze_optimization_batch(files, initial_capital)
